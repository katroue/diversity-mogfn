# Sampling Ablation Configuration
# Tests different sampling strategies and parameters

# Base configuration (same for all experiments)
fixed:
  env_name: 'hypergrid'
  env_kwargs:
    ndim: 8
    height: 8
    R0: 0.01
    R1: 0.5
    R2: 2.0
  
  # Training parameters (SAME AS CAPACITY ABLATION)
  num_iterations: 4000  # Same as capacity ablation (4000) for fair comparison, testing with 1000 iterations
  batch_size: 128  # Default batch size (can be overridden per experiment)
  lr: 0.001
  
  # Evaluation
  num_samples: 1000  # Number of samples for evaluation
  eval_every: 500  # Evaluate every 500 iterations, testing with evaluations every 200 iterations
  
  # Model architecture (BEST FROM CAPACITY ABLATION)
  hidden_dim: 128
  num_layers: 4
  conditioning: 'concat'  # Best from capacity ablation
  
  # Logging
  wandb: false
  save_trajectories: true

# Seeds for statistical robustness
seeds: [42, 123, 456, 789, 1011]

# Experiments: Different sampling strategies
experiments:
  
  # ========================================
  # 1. EXPLORATION TEMPERATURE
  # ========================================

  # Note : Temperature affects exploration vs exploitation.
  # Low temp = more deterministic (exploit), High temp = more random (explore).
  # probs = softmax(logits / τ), where τ = temperature.
  
  - name: 'temp_low'
    temperature: 0.5  # Low temp = more deterministic, less exploration
    sampling_strategy: 'categorical'
    description: 'Low temperature - exploit mode'
  
  - name: 'temp_medium'
    temperature: 1.0  # Standard temperature
    sampling_strategy: 'categorical'
    description: 'Medium temperature - balanced'
  
  - name: 'temp_high' # Best configuration according to sampling ablation results ********
    temperature: 2.0  # High temp = more random, more exploration
    sampling_strategy: 'categorical'
    description: 'High temperature - explore mode'
  
  - name: 'temp_very_high'
    temperature: 5.0  # Very high temp = nearly uniform sampling
    sampling_strategy: 'categorical'
    description: 'Very high temperature - maximum exploration'
  
  # ========================================
  # 2. SAMPLING STRATEGIES
  # ========================================
  
  - name: 'greedy'
    temperature: 1.0
    sampling_strategy: 'greedy'  # Always take argmax
    description: 'Greedy sampling - deterministic'
  
  - name: 'categorical'
    temperature: 1.0
    sampling_strategy: 'categorical'  # Sample from distribution
    description: 'Categorical sampling - stochastic'
  
  - name: 'top_k'
    temperature: 1.0
    sampling_strategy: 'top_k'
    top_k: 3  # Sample from top-3 actions
    description: 'Top-K sampling with K=3'
  
  - name: 'top_p'
    temperature: 1.0
    sampling_strategy: 'nucleus'  # Nucleus/top-p sampling
    top_p: 0.9  # Sample from top 90% probability mass
    description: 'Nucleus sampling with p=0.9'
  
  # ========================================
  # 3. ON-POLICY VS OFF-POLICY
  # ========================================
  
  - name: 'on_policy_pure'
    off_policy_ratio: 0.0  # 100% on-policy
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: 'Pure on-policy training'

  - name: 'off_policy_10' # second best configuration according to sampling ablation results ********
    off_policy_ratio: 0.1  # 10% random exploration
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: '10% off-policy (random) exploration'
  
  - name: 'off_policy_25'
    off_policy_ratio: 0.25  # 25% random exploration
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: '25% off-policy exploration'
  
  - name: 'off_policy_50'
    off_policy_ratio: 0.5  # 50% random exploration
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: '50% off-policy exploration'
  
  # ========================================
  # 4. PREFERENCE DIVERSITY
  # ========================================
  
  - name: 'pref_uniform'
    preference_distribution: 'uniform'  # Uniform over simplex
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: 'Uniform preference distribution'
  
  - name: 'pref_dirichlet_low'
    preference_distribution: 'dirichlet'
    dirichlet_alpha: 0.5  # Low alpha = concentrated at corners
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: 'Dirichlet α=0.5 (corner preferences)'
  
  - name: 'pref_dirichlet_medium'
    preference_distribution: 'dirichlet'
    dirichlet_alpha: 1.5  # Medium alpha = balanced
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: 'Dirichlet α=1.5 (balanced preferences)'
  
  - name: 'pref_dirichlet_high'
    preference_distribution: 'dirichlet'
    dirichlet_alpha: 5.0  # High alpha = concentrated at center
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: 'Dirichlet α=5.0 (center preferences)'
  
  # ========================================
  # 5. BATCH SIZE EFFECTS
  # ========================================
  
  - name: 'batch_32'
    batch_size: 32
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: 'Small batch size (32)'
  
  - name: 'batch_64'
    batch_size: 64
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: 'Medium batch size (64)'
  
  - name: 'batch_256'
    batch_size: 256
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: 'Large batch size (256)'
  
  - name: 'batch_512'
    batch_size: 512
    temperature: 1.0
    sampling_strategy: 'categorical'
    description: 'Very large batch size (512)'
  
  # ========================================
  # 6. COMBINED BEST PRACTICES
  # ========================================
  
  - name: 'diverse_sampling' # best configuration according to sampling ablation results ********
    temperature: 2.0
    sampling_strategy: 'nucleus'
    top_p: 0.9
    off_policy_ratio: 0.15
    preference_distribution: 'dirichlet'
    dirichlet_alpha: 1.5
    description: 'Combined diversity-promoting strategies'
  
  - name: 'quality_sampling'
    temperature: 0.7
    sampling_strategy: 'top_k'
    top_k: 3
    off_policy_ratio: 0.05
    preference_distribution: 'uniform'
    description: 'Combined quality-promoting strategies'

# Total experiments: 24 configurations × 5 seeds = 120 experiments
# Expected runtime: ~48 hours (2 days) for all 120 experiments
# Each experiment: ~24 minutes (same as capacity ablation)
# Quality: 97% convergence (excellent for HyperGrid 8×8)

# Metrics to compare:
# - Diversity metrics: TDS, MCE, PFS, PAS
# - Quality metrics: Hypervolume, Pareto coverage
# - Sample efficiency: Final performance vs training steps
# - Duplicate rate: pmd_duplicate_pct