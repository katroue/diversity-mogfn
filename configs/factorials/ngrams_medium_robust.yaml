# ============================================================================
# MEDIUM ROBUST CONFIGURATION (N-GRAMS)
# ============================================================================
# Purpose: Validate medium capacity as a robust default across all tasks
#
# Medium Configuration (Robust Default):
#   - Model: 64 hidden dimensions, 3 layers MLP (MEDIUM capacity)
#   - Sampling: Low temperature (τ=1.0)
#   - Loss: Trajectory Balance (TB) with 0.01 regularization
#   - Policy: 10% off-policy ratio
#   - Conditioning: FiLM mechanism
#
# Rationale: Medium capacity provides robust performance across all tasks
#            without task-specific tuning. Serves as practical default
#            recommendation for practitioners.
#
# Performance from Factorial Analysis (medium_tb condition):
#   - QDS: 0.5590 (rank 3/28 - excellent)
#   - MCE: 0.5901 (high mode coverage)
#   - Hypervolume: 1.4462 (excellent quality)
#   - TDS: 0.5950 (good trajectory diversity)
#
# Comparison to Task-Specific Best (Small: 32×2):
#   - QDS: 0.5759 (best) vs 0.5590 (medium) = -2.9% difference
#   - Medium achieves 97.1% of task-specific optimal performance
#   - Advantage: Works well across all tasks without task-specific tuning
#
# Experimental Design: 1 condition × 5 seeds = 5 runs
# ============================================================================

experiment_name: "ngrams_medium_robust"
study_type: "validation"

# ============================================================================
# FIXED PARAMETERS (Medium robust configuration)
# ============================================================================

fixed:
  # Task: N-grams generation
  environment: 'ngrams'
  ngram_length: 4
  vocab_size: 4  # A, B, C, D
  num_objectives: 2

  # Model architecture (MEDIUM capacity - robust default)
  hidden_dim: 64
  num_layers: 3
  conditioning: "film"  # FiLM conditioning mechanism
  activation: "relu"

  # Sampling strategy (optimal for medium capacity)
  temperature_sampling: 1.0  # Low temperature (optimal from factorial)
  sampling_strategy: "categorical"

  # Loss function (Trajectory Balance)
  loss_function: "trajectory_balance"  # TB loss
  loss_params:
    log_reward_clip: 10.0
  regularization: "entropy"
  regularization_params:
    beta: 0.01  # 0.01 regularization
  modifications: "none"
  modifications_params: {}

  # Preference sampling
  preference_distribution: "dirichlet"
  dirichlet_alpha: 1.5
  num_preferences_per_batch: 16

  # Training parameters
  max_iterations: 8000
  batch_size: 128
  optimizer: "adam"
  learning_rate: 0.001
  gradient_clip: 10.0
  off_policy_ratio: 0.1  # 10% off-policy

  # Evaluation
  eval_every: 500
  eval_samples: 1000
  final_eval_samples: 10000

  # Seeds (same as factorial study)
  num_seeds: 5
  base_seed: 42

# ============================================================================
# SINGLE CONDITION: Medium Robust Configuration
# ============================================================================

factors:
  # Single factor with one level (medium robust config)
  config:
    description: "Medium capacity robust default configuration"
    levels:
      medium_robust:
        label: "Medium (64×3, TB, FiLM)"
        # All parameters are in fixed section
        description: "Robust default: medium_tb"

# ============================================================================
# EXPERIMENTAL CONDITIONS (Single condition)
# ============================================================================

conditions:
  - name: "medium_robust"
    config: "medium_robust"

# ============================================================================
# METRICS TO EVALUATE
# ============================================================================

metrics:
  primary:
    - quality_diversity_score  # QDS: PRIMARY selection criterion
    - mode_coverage_entropy  # MCE: Spatial diversity (high for n-grams)
    - hypervolume  # Quality: Pareto front coverage
    - trajectory_diversity_score  # TDS: Path diversity

  secondary:
    - preference_aligned_spread  # PAS: Diversity aligned with preferences
    - pareto_front_smoothness  # PFS: Preference alignment
    - flow_concentration_index  # FCI: Flow concentration
    - diversity_efficiency_ratio  # DER: Diversity per computation
    - pairwise_minimum_distance  # PMD: Objective space spread
    - replay_buffer_diversity  # RBD: Training sample diversity

# ============================================================================
# VALIDATION OBJECTIVES
# ============================================================================

validation:
  purpose: "Validate medium capacity as robust default for N-grams"

  hypotheses:
    h1_qds:
      statement: "Medium config achieves near-optimal Quality-Diversity Score"
      prediction: "QDS > 0.53"
      rationale: "Medium capacity (64×3) achieves 97.1% of task-specific best"

    h2_mce:
      statement: "Medium config achieves high Mode Coverage Entropy"
      prediction: "MCE > 0.55"
      rationale: "Medium capacity enables good mode exploration"

    h3_hypervolume:
      statement: "Medium config achieves high Hypervolume"
      prediction: "Hypervolume > 1.40"
      rationale: "TB loss optimizes Pareto front quality"

    h4_robustness:
      statement: "Medium config shows stable performance across seeds"
      prediction: "Coefficient of variation < 0.20"
      rationale: "Medium capacity balances expressiveness and generalization"

  expected_performance:
    qds_mean: ">0.53"
    qds_std: "<0.05"
    mce_mean: ">0.55"
    mce_std: "<0.05"
    hypervolume_mean: ">1.40"
    hypervolume_std: "<0.10"
    tds_mean: ">0.55"
    tds_std: "<0.05"

  comparison_baseline:
    description: "Compare against task-specific best (Small: 32×2, τ=2.0)"
    expectation: "Medium should achieve >95% of task-specific best QDS"

# ============================================================================
# COMPUTATIONAL RESOURCES
# ============================================================================

resources:
  total_runs: 5  # 1 condition × 5 seeds
  estimated_time_per_run: "16 minutes"  # 20000 iterations on n-grams
  total_time_sequential: "1.3 hours"
  total_time_parallel: "16 minutes"  # With 5 parallel jobs

  storage_per_run: "~16 MB"
  total_storage: "~80 MB"

# ============================================================================
# SUCCESS CRITERIA
# ============================================================================

success_criteria:

  minimum_performance:
    qds: 0.53  # Must exceed 0.53 (95% of task-specific best)
    mce: 0.55  # Must exceed 0.55 for mode coverage
    hypervolume: 1.30  # Must exceed 1.30 for Pareto quality
    tds: 0.55  # Must exceed 0.55 for trajectory diversity

  robustness:
    description: "Medium as robust default across tasks"
    max_coefficient_of_variation: 0.20  # CV = std/mean < 0.20

  comparison_to_best:
    description: "Performance relative to task-specific best"
    min_qds_ratio: 0.95  # Must achieve >95% of task-specific best QDS
