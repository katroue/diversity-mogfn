{
  "task": "hypergrid",
  "grid_size": [
    32,
    32
  ],
  "capacity": "medium",
  "arch_type": "concat",
  "hidden_dim": 128,
  "num_layers": 4,
  "activation": "relu",
  "preference_distribution": "dirichlet",
  "temperature": 2.0,
  "sampling_strategy": "categorical",
  "dirichlet_alpha": 1.5,
  "num_preferences_per_batch": 16,
  "sampling_schedule": "uniform",
  "num_iterations": 4000,
  "batch_size": 128,
  "optimizer": "adam",
  "learning_rate": 0.001,
  "lr_schedule": "constant",
  "gradient_clip": 10.0,
  "eval_every": 500,
  "eval_samples": 1000,
  "final_eval_samples": 10000,
  "num_seeds": 5,
  "base_seed": 42,
  "name": "temperature_scaled_logits",
  "group": "loss_modifications",
  "seed": 153,
  "modifications": "temperature_scaled_logits",
  "modifications_type": "temperature_scaling",
  "modifications_params": {
    "temperature": 2.0,
    "apply_to": "logits"
  },
  "modifications_label": "Temp-Scale(\u03c4=2.0)",
  "base_loss": "subtrajectory_balance_09",
  "base_loss_type": "subtrajectory_balance",
  "base_loss_params": {
    "lambda_": 0.9,
    "log_reward_clip": 10.0
  },
  "base_loss_label": "SubTB(\u03bb=0.9)",
  "regularization": "entropy_001",
  "regularization_type": "entropy",
  "regularization_params": {
    "beta": 0.01,
    "entropy_type": "policy"
  },
  "regularization_label": "Entropy(\u03b2=0.01)"
}