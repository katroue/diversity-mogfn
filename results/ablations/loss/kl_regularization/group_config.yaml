fixed:
  activation: relu
  arch_type: concat
  base_seed: 42
  batch_size: 128
  capacity: medium
  dirichlet_alpha: 1.5
  eval_every: 500
  eval_samples: 1000
  final_eval_samples: 10000
  gradient_clip: 10.0
  grid_size:
  - 32
  - 32
  hidden_dim: 128
  learning_rate: 0.001
  lr_schedule: constant
  num_iterations: 4000
  num_layers: 4
  num_preferences_per_batch: 16
  num_seeds: 5
  optimizer: adam
  preference_distribution: dirichlet
  sampling_schedule: uniform
  sampling_strategy: categorical
  task: hypergrid
  temperature: 2.0
group:
  description: Test KL divergence to uniform policy
  fixed:
    base_loss: subtrajectory_balance_09
    modifications: standard
  group: kl_regularization
  vary:
    regularization:
    - none
    - kl_uniform_001
    - kl_uniform_01
timestamp: '2025-11-02T14:38:12.854525'
