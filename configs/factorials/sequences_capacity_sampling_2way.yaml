# ============================================================================
# TWO-WAY FACTORIAL: CAPACITY × SAMPLING (DNA SEQUENCES)
# ============================================================================
# Purpose: Test interaction between model capacity and sampling temperature
#          on the N-grams sequence generation environment
#
# Research Question: Does optimal sampling strategy depend on model capacity
#                   for discrete sequence generation?
# Hypothesis: Small models need lower temperature (limited capacity to explore)
#            Large models benefit from higher temperature (more capacity)
#
# Design: 3 × 3 factorial
#   Factor A (Capacity): small, medium, large
#   Factor B (Temperature): 1.0, 2.0, 5.0
#   Total: 9 combinations × 5 seeds = 45 runs
# ============================================================================

experiment_name: "sequences_capacity_sampling_2way"
study_type: "factorial"

# ============================================================================
# FIXED PARAMETERS (Controlled across all conditions)
# ============================================================================

fixed:
  # Task: DNA sequences generation
  environment: 'sequences'
  seq_length: 20
  temperaturee: 37.0  # Celsius for NUPACK stability calculations
  use_nupack: True
  objective_properties:
    - "free_energy"
    - "num_baise_pairs"
    - "inverse_length"

  # Loss function (BEST from loss ablation)
  loss_function: "subtrajectory_balance"
  loss_params:
    lambda_: 0.9
    log_reward_clip: 10.0
  regularization: "entropy"
  regularization_params:
    beta: 0.01
  modifications: "none"
  modifications_params: {}

  # Preference sampling (FIXED)
  preference_distribution: "dirichlet"
  dirichlet_alpha: 1.5
  num_preferences_per_batch: 16
  sampling_strategy: "categorical"  # Always categorical

  # Training
  max_iterations: 10000  # Increased from 4000 due to 64x larger state space
  batch_size: 128
  optimizer: "adam"
  learning_rate: 0.001
  gradient_clip: 10.0

  # Evaluation
  eval_every: 500
  eval_samples: 1000
  final_eval_samples: 10000

  # Seeds
  num_seeds: 5
  base_seed: 42

# ============================================================================
# FACTORIAL DESIGN: Two Factors
# ============================================================================

factors:

  # Factor A: Model Capacity
  capacity:
    description: "Model size (hidden dim × num layers)"
    levels:

      small:
        label: "Small (64×2)"
        hidden_dim: 64
        num_layers: 2
        conditioning: "concat"
        activation: "relu"
        num_parameters: ~1.3K  # Approximate (state_dim = 9 for seq_length=8)

      medium:
        label: "Medium (128×4)"
        hidden_dim: 128
        num_layers: 4
        conditioning: "concat"
        activation: "relu"
        num_parameters: ~70K  # Approximate

      large:
        label: "Large (256×6)"
        hidden_dim: 256
        num_layers: 6
        conditioning: "concat"
        activation: "relu"
        num_parameters: ~530K  # Approximate

  # Factor B: Sampling Temperature
  temperature:
    description: "Exploration temperature for action sampling"
    levels:

      low:
        label: "Low (τ=1.0)"
        temperature: 1.0
        description: "Balanced exploration-exploitation"

      high:
        label: "High (τ=2.0)"
        temperature: 2.0
        description: "Increased exploration"

      very_high:
        label: "Very High (τ=5.0)"
        temperature: 5.0
        description: "Maximum exploration"

# ============================================================================
# EXPERIMENTAL CONDITIONS (All 9 combinations)
# ============================================================================

conditions:
  # Format: capacity x temperature

  # Small capacity × All temperatures
  - name: "small_low"
    capacity: "small"
    temperature: "low"

  - name: "small_high"
    capacity: "small"
    temperature: "high"

  - name: "small_veryhigh"
    capacity: "small"
    temperature: "very_high"

  # Medium capacity × All temperatures
  - name: "medium_low"
    capacity: "medium"
    temperature: "low"

  - name: "medium_high"
    capacity: "medium"
    temperature: "high"

  - name: "medium_veryhigh"
    capacity: "medium"
    temperature: "very_high"

  # Large capacity × All temperatures
  - name: "large_low"
    capacity: "large"
    temperature: "low"

  - name: "large_high"
    capacity: "large"
    temperature: "high"

  - name: "large_veryhigh"
    capacity: "large"
    temperature: "very_high"

# ============================================================================
# METRICS
# ============================================================================

metrics:
  primary:
    - mode_coverage_entropy  # MCE: How many unique sequences
    - preference_aligned_spread  # PAS: Diversity aligned with preferences
    - trajectory_diversity_score  # TDS: Path diversity
    - flow_concentration_index  # FCI: How concentrated are flows
    - quality_diversity_score  # QDS: Combined metric

  secondary:
    - hypervolume  # Quality: Pareto front coverage
    - diversity_efficiency_ratio  # DER: Diversity per computation
    - replay_buffer_diversity  # RBD: Training sample diversity

# ============================================================================
# ANALYSIS PLAN
# ============================================================================

analysis:

  research_questions:

    rq1:
      question: "Does capacity have a main effect on diversity?"
      test: "one_way_anova"
      factor: "capacity"
      metric: "mode_coverage_entropy"

    rq2:
      question: "Does temperature have a main effect on diversity?"
      test: "one_way_anova"
      factor: "temperature"
      metric: "mode_coverage_entropy"

    rq3:
      question: "Is there an interaction between capacity and temperature?"
      test: "two_way_anova"
      factors: ["capacity", "temperature"]
      metric: "mode_coverage_entropy"
      interaction_term: "capacity:temperature"

  statistical_tests:

    - name: "factorial_anova"
      test: "two_way_anova"
      formula: "mce ~ C(capacity) + C(temperature) + C(capacity):C(temperature)"
      alpha: 0.05

    - name: "capacity_posthoc"
      test: "tukey_hsd"
      factor: "capacity"
      metric: "mce"

    - name: "temperature_posthoc"
      test: "tukey_hsd"
      factor: "temperature"
      metric: "mce"

# ============================================================================
# HYPOTHESES
# ============================================================================

hypotheses:

  h1_main_capacity:
    statement: "Model capacity has a significant main effect on diversity"
    prediction: "Medium > Small, Large ≈ Medium (diminishing returns)"
    rationale: "More capacity enables learning diverse sequence generation policies"

  h2_main_temperature:
    statement: "Temperature has a significant main effect on diversity"
    prediction: "High (τ=2.0) > Low (τ=1.0), Very High (τ=5.0) ≈ High"
    rationale: "Higher temperature increases exploration in discrete action space"

  h3_interaction:
    statement: "There is an interaction between capacity and temperature"
    prediction: "Small models: Low > High (limited capacity), Large models: High > Low"
    rationale: "Small models can't leverage high exploration; large models need it to explore discrete space"
    expected_pattern: "Non-parallel lines in interaction plot"

  h4_discrete_hypothesis:
    statement: "N-grams shows stronger interaction than continuous HyperGrid"
    prediction: "Interaction effect larger for N-grams due to discrete action space"
    rationale: "Discrete actions require more exploration, magnifying capacity-temperature interaction"

# ============================================================================
# COMPUTATIONAL RESOURCES
# ============================================================================

resources:
  total_runs: 45  # 9 conditions × 5 seeds
  estimated_time_per_run: "30 minutes"  # 10000 iterations
  total_time_sequential: "23 hours"
  total_time_parallel: "2.3 hours"  # With 10 parallel jobs

  recommended_parallelization:
    strategy: "condition_parallel"
    max_parallel: 10

  storage_per_run: "~30 MB"  # Smaller than HyperGrid (shorter trajectories)
  total_storage: "~1.4 GB"

# ============================================================================
# EXPECTED RESULTS
# ============================================================================

expected_results:

  scenario_no_interaction:
    description: "Factors are independent (additive effects)"
    interaction_plot: "Parallel lines"
    implication: "Optimal settings independent: use Medium + High"

  scenario_interaction:
    description: "Factors depend on each other (multiplicative effects)"
    interaction_plot: "Non-parallel or crossing lines"
    implication: "Optimal settings depend on context"
    examples:
      - "Small models work best with Low temp"
      - "Large models need High temp to explore discrete space"

  best_case:
    condition: "large_high"
    expected_mce: ">0.4"  # May be lower than HyperGrid (more constrained space)
    expected_qds: ">0.6"

  worst_case:
    condition: "small_veryhigh"
    expected_mce: "<0.15"
    expected_qds: "<0.35"
    rationale: "Small capacity can't handle high exploration in discrete space"